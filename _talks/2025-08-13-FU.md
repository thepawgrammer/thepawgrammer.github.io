---
title: "Federated Unlearning: Concept & Challenges"
date: 2025-08-13
slides: /files/slides/20250813 - Federated Unlearning Concept.pdf
layout: talk
collection: talks
author_profile: true
---

**Summary:**  
In preparation for a lab meeting, I studied the concept of Federated Unlearning, which extends the idea of â€œmachine unlearningâ€ to federated learning environments. While federated learning protects raw data by keeping it on clients, requests such as the â€œRight to be Forgottenâ€ raise a crucial question: How can we safely remove the influence of specific data or clients from a trained federated model? This summary is based on the PEPR â€™24 talk Learning and Unlearning Your Data in Federated Settings (USENIX).  

ğŸ”‘ **Research Question:** 
- Can federated learning systems *support safe and efficient data deletion* without full retraining?   

âš™ï¸ **Conceptual Approaches:** 
  - **Passive Unlearning:**  
    - Server-only (leveraging stored updates)
    - Client-aided (clients assist with gradient/history)
  - **Active Unlearning:** 
    - Server and clients collaboratively remove the influence of target data.
  - **Level of Unlearning:**
    - Record-level, class-level, or client-level unlearning

ğŸ“Š **Key Insightes:**  
  - Retraining is reliable but computationally prohibitive.  
  - Approximate unlearning can preserve accuracy but may weaken guarantees.  
  - Privacy, consistency, and efficiency must be carefully balanced.  
  - Lack of formal proof of unlearning remains a major challenge.   

âš ï¸ **Limitations & Open Challenges:**  
  - **Verifiability:** proving that unlearning actually occurred.  
  - **Dynamic participation:** handling clients joining or leaving.  
  - Fairness and explainability remain underexplored.  
  - **New privacy risks** may arise during the unlearning process itself.

ğŸ¥ **Reference:**
  - PEPR '24 - Learning and Unlearning Your Data in Federated Settings  

**Slides:**  
[PDF (Korean) Download](/files/slides/20250813 - Federated Unlearning Concept.pdf)